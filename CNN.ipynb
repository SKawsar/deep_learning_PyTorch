{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:19:45.088302Z",
     "start_time": "2023-11-04T21:19:44.843896Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchmetrics import Precision, Recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(45),\n",
    "    transforms.RandomAutocontrast(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((64, 64))\n",
    "])\n",
    "\n",
    "dataset_train = ImageFolder(\n",
    "  \"clouds/clouds_train\",\n",
    "  transform=train_transforms,\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "  dataset_train, shuffle=True, batch_size=16\n",
    ")\n",
    "\n",
    "# image, label = next(iter(dataloader_train))\n",
    "# # Reshape the image tensor\n",
    "# image = image.squeeze().permute(1, 2, 0)\n",
    "# # Display the image\n",
    "# plt.imshow(image)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:17:33.845387Z",
     "start_time": "2023-11-04T21:17:33.835260Z"
    }
   },
   "id": "cddadc0abb6178e9"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        # Define feature extractor\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ELU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "        # Define classifier\n",
    "        self.classifier = nn.Linear(64*16*16, num_classes)\n",
    "    \n",
    "    def forward(self, x):  \n",
    "        # Pass input through feature extractor and classifier\n",
    "        x = self.feature_extractor(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:17:33.845503Z",
     "start_time": "2023-11-04T21:17:33.836493Z"
    }
   },
   "id": "9c5e450e5c5d027c"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.9412\n",
      "Epoch 2, Loss: 1.5489\n",
      "Epoch 3, Loss: 1.3602\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "net = Net(num_classes=7)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(3):\n",
    "    running_loss = 0.0\n",
    "    # Iterate over training batches\n",
    "    for images, labels in dataloader_train:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader_train)\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:17:38.589950Z",
     "start_time": "2023-11-04T21:17:33.838292Z"
    }
   },
   "id": "ea7a6f508c0a148e"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "#\n",
    "# NO DATA AUGMENTATION AT TEST TIME\n",
    "#\n",
    "transforms.ToTensor(),\n",
    "transforms.Resize((64, 64))\n",
    "])\n",
    "\n",
    "dataset_test = ImageFolder(\"clouds/clouds_test\",\n",
    "                   transform=test_transforms)\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "  dataset_test, shuffle=True, batch_size=16\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:23:55.367069Z",
     "start_time": "2023-11-04T21:23:55.348526Z"
    }
   },
   "id": "13ac4d49f2e236dc"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kawsar/anaconda3/envs/python_3_10/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6055881381034851\n",
      "Recall: 0.44056206941604614\n"
     ]
    }
   ],
   "source": [
    "# Define metrics\n",
    "metric_precision = Precision(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "metric_recall = Recall(task=\"multiclass\", num_classes=7, average=\"macro\")\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "        metric_recall(preds, labels)\n",
    "\n",
    "precision = metric_precision.compute()\n",
    "recall = metric_recall.compute()\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:23:58.412721Z",
     "start_time": "2023-11-04T21:23:57.306941Z"
    }
   },
   "id": "6d9830013ff38b6f"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cirriform clouds': 0.25, 'clear sky': 1.0, 'cumulonimbus clouds': 0.5833333134651184, 'cumulus clouds': 0.6451612710952759, 'high cumuliform clouds': 0.3913043439388275, 'stratiform clouds': 1.0, 'stratocumulus clouds': 0.3693181872367859}\n"
     ]
    }
   ],
   "source": [
    "# Define precision metric\n",
    "metric_precision = Precision(task=\"multiclass\", \n",
    "                            num_classes=7, \n",
    "                            average=None)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader_test:\n",
    "        outputs = net(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        metric_precision(preds, labels)\n",
    "precision = metric_precision.compute()\n",
    "\n",
    "# Get precision per class\n",
    "precision_per_class = {\n",
    "    k: precision[v].item()\n",
    "    for k, v \n",
    "    in dataset_test.class_to_idx.items()\n",
    "}\n",
    "print(precision_per_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-04T21:26:50.555218Z",
     "start_time": "2023-11-04T21:26:49.528399Z"
    }
   },
   "id": "f18869f5990ad04"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fcbc068eb0590ca3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
